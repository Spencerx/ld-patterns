<sect1 id="parallel-retrieval">
  <title>Parallel Retrieval</title>
  <para> 
   <emphasis>How can we improve performance of an application dynamically retrieving Linked Data?</emphasis>
  </para>

  <sect2><title>Context</title>
  <para>An application that draws on data from the web may typically be retrieving a number of 
  different resources. This is especially true if using the <link linkend="follow-your-nose">Follow Your Nose</link> 
  pattern to discover data</para>
  </sect2>

  <sect2><title>Solution</title>
  <para>Use several workers to make parallel GET requests, with each work writing into a shared RDF graph</para>
  </sect2>

  <sect2><title>Example(s)</title>
  <para>Most good HTTP client libraries will support parallelisation of HTTP requests. E.g. PHP's 
  <ulink linkend="http://us.php.net/manual/en/function.curl-multi-init.php">curl_multi</ulink> or Ruby's 
  <ulink linkend="https://github.com/dbalatero/typhoeus">typhoeus</ulink> library.</para>
  </sect2>

  <sect2><title>Discussion</title>
  <para>Parallelisation of HTTP requests can greatly reduce retrieval times, e.g. to time of the single longest 
  GET request.</para>
  <para>By combining this approach with <link linkend="resource-caching">Resource Caching</link> of the individual 
  responses, an application can maintain a local cache of the most requested data, which are then combined 
  and parsed into a single RDF graph for driving application behaviour.</para>
  <para>Parallelisation is particularly useful for AJAX based applications as browsers are particularly well optimized 
  for making a large number of parallel HTTP requests.</para>
  </sect2>

  <sect2><title>Related</title>
  <itemizedlist>
  <listitem><link linkend="follow-your-nose">Follow Your Nose</link></listitem>
  <listitem><link linkend="parallel-loading">Parallel Loading</link></listitem>
  </itemizedlist>
  </sect2>

</sect1>
